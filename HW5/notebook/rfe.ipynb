{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "from natsort import natsorted\n",
    "from IPython.display import display\n",
    "from scipy.stats import bootstrap\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 10) (1000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "X, y = make_classification(n_samples=1000, n_features=10, \n",
    "n_informative=5, n_redundant=5, random_state=1)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate RFE for classification\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5,\n",
    "    random_state=1)\n",
    "# create pipeline\n",
    "rfe = RFE(estimator=DecisionTreeClassifier(), n_features_to_select=5) \n",
    "model = DecisionTreeClassifier()\n",
    "pipeline = Pipeline(steps=[('s',rfe),('m',model)])\n",
    "# evaluate model\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1) # report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_5fold_score(X, y, p):\n",
    "    '''Get 5-fold score(1 - error rate) associated with speficed number of features p\n",
    "    '''\n",
    "    total_score = 0 \n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=11)\n",
    "    for ti, vi in skf.split(X, y):\n",
    "        X_train, X_val = X.iloc[ti, :], X.iloc[vi, :]\n",
    "        y_train, y_val = y[ti], y[vi]\n",
    "        model = LogisticRegression(C=10000, solver='liblinear', max_iter=50)\n",
    "        rfe = RFE(model, n_features_to_select=p)\n",
    "        rfe = rfe.fit(X_train, y_train)\n",
    "        total_score += rfe.score(X_val, y_val)\n",
    "\n",
    "    return total_score/5\n",
    "\n",
    "def get_best_p(X, y):\n",
    "    '''Get the \"best\" number of features p which has the largest score\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : {array-like, data frame} of shape (n_samples, n_features)\n",
    "        Training vector, where `n_samples` is the number of samples and\n",
    "        `n_features` is the number of features.\n",
    "    y : array-like of shape (n_samples,)\n",
    "        Target vector relative to X.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    best_p : number of features which gets the largest score (1 - error rate)\n",
    "    max_score : maximum of 5-fold average score\n",
    "    '''\n",
    "    best_p = 1\n",
    "    max_score = 0\n",
    "    for p in range(1, X.shape[1]):\n",
    "        cur_score = get_5fold_score(X, y, p)\n",
    "        if(cur_score > max_score):\n",
    "            best_p = p\n",
    "            max_score = cur_score\n",
    "\n",
    "    return best_p, max_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "y = np.array(train_label)\n",
    "bl = 1 # best number to break time series -- l\n",
    "bp = 1 # best number of features -- p\n",
    "max_score = 0 # largest score\n",
    "l = 1\n",
    "for df in TDF_df_list: \n",
    "    X = df.iloc[train_index, :]\n",
    "    cur_p, cur_score = get_best_p(X, y)\n",
    "    print(l)\n",
    "    if cur_score > max_score:\n",
    "        bl = l\n",
    "        bp = cur_p\n",
    "        max_score = cur_score\n",
    "    l += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('torchenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c71e970b376e5910de56d332af36cb508b823811ace826c2f1193ceeb2dcc3e7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
